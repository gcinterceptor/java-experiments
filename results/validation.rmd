---
title: "GCI Simulator Validation"
author: "Daniel Fireman (danielfireman@gmail.com)"
date: "March, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F)
knitr::opts_chunk$set(warning=F)
knitr::opts_chunk$set(cache=T)

require(gridExtra)
require(boot)
require(dplyr)
require(stringr)
require(cowplot)
require(ggplot2)

source("functions.R")

RESAMPLES <- 1000
WARMUP_SECS <- 120
```

# Simulator Validation

The output of the simulator and the independent variable of our 1-factor
experiment is the latency of one request. We would like to determine if the
simulator is valid. We are going to this by comparing the simulator and
experiment results. 

This first valation refers to a 1-factor experiment and the independent variable
is the latency (continuous variable, positive integer).

**Hyphotesis**

* $H_{0}$: The simulated latency is different from experimental latency.

```{r}
al1.exp.gci <- accesslog("1i", "gci_T80_Java9_WithFullGC", 4, WARMUP_SECS)
al1.exp.nogci <- accesslog("1i", "nogci_T80_Java9_WithFullGC", 4, WARMUP_SECS)

al1.sim.gci <- rbind(
  read.csv("1i/sim_lb_gci_1.csv"),
  read.csv("1i/sim_lb_gci_2.csv"),
  read.csv("1i/sim_lb_gci_3.csv"),
  read.csv("1i/sim_lb_gci_4.csv"))
al1.sim.gci$latency <- as.integer(al1.sim.gci$latency*1000)

al1.sim.nogci <- rbind(
  read.csv("1i/sim_lb_nogci_1.csv"),
  read.csv("1i/sim_lb_nogci_2.csv"),
  read.csv("1i/sim_lb_nogci_3.csv"),
  read.csv("1i/sim_lb_nogci_4.csv"))
al1.sim.nogci$latency <- as.integer(al1.sim.nogci$latency*1000)

# Only consider latency of successfull requests.
al1.sim.gci <- filter(al1.sim.gci, done == "True")
al1.sim.nogci <- filter(al1.sim.nogci, done == "True")
al1.exp.gci <- filter(al1.exp.gci, status == 200)
al1.exp.nogci <- filter(al1.exp.nogci, status == 200)
```

## Graphical Comparison

It is important for the simulator needs to be a good model for the median and tail latency. Thus, we
performed statistical tests at both parts of the latency distribution. We analyzed 3 parts of the tail:
90, 99, 99.9 percentile.

Confidence intervals for the median where calculated using the Wilcoxon signed (non-parametric) method. Confidence intervals at the tail where calculated using bootstrap resampling basic (1000 samples).

### Treatment Group

```{r, fig.asp=0.5, fig.align="center"}
# If you don't trim the library, your computer could die trying to resample.
al1.cmp <- rbind(
  data.frame("latency"=sample(al1.sim.gci$latency, 4000), type="Simulator"),
  data.frame("latency"=sample(al1.exp.gci$request_time, 4000), type="Experiment"))

grid.arrange(
  ggplot(al1.cmp, aes(type, latency)) +
    geom_boxplot() +
    ggtitle("Summary") +
    ylab("Latency(ms)") +
    xlab("Type"),
   ggplot(al1.cmp, aes(latency, linetype=type)) +
    stat_ecdf() +
    ggtitle("ECDF") +
    xlab("Latency(ms)") +
    ylab("ECDF") +
    theme(legend.position="top"),
  ggplot(al1.cmp) +
    stat_qq(aes(sample=latency, colour=type)) +
    ggtitle("QQPLOT") +
    theme(legend.position="top"),
  ncol=3)

grid.arrange(
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=median, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.median, geom="errorbar", width=0.05) +
    ggtitle("Median") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p99, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p99, geom="errorbar", width=0.05) +
    ggtitle("99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p999, geom="errorbar", width=0.05) +
    ggtitle("99.9 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p9999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p9999, geom="errorbar", width=0.05) +
    ggtitle("99.99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ncol=2,
  nrow=2)
```

### Control Group

```{r, fig.asp=0.5, fig.align="center"}
al1.nogci.cmp <- rbind(
  data.frame("latency"=sample(al1.sim.nogci$latency, 4000), type="Simulator"),
  data.frame("latency"=sample(al1.exp.nogci$request_time, 4000), type="Experiment"))

grid.arrange(
  top = "Control Group",
  ggplot(al1.nogci.cmp, aes(type, latency)) +
    geom_boxplot() +
    ggtitle("Summary") +
    ylab("Latency(ms)") +
    xlab("Type"),
   ggplot(al1.nogci.cmp, aes(latency, linetype=type)) +
    stat_ecdf() +
    ggtitle("ECDF") +
    xlab("Latency(ms)") +
    ylab("ECDF") +
    theme(legend.position="top"),
  ggplot(al1.nogci.cmp) +
    stat_qq(aes(sample=latency, colour=type)) +
    ggtitle("QQPLOT") +
    theme(legend.position="top"),
  ncol=3)

grid.arrange(
  ggplot(al1.nogci.cmp, aes(type, latency)) +
    stat_summary(fun.y=median, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.median, geom="errorbar", width=0.05) +
    ggtitle("Median") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.nogci.cmp, aes(type, latency)) +
    stat_summary(fun.y=p99, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p99, geom="errorbar", width=0.05) +
    ggtitle("99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.nogci.cmp, aes(type, latency)) +
    stat_summary(fun.y=p999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p999, geom="errorbar", width=0.05) +
    ggtitle("99.9 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.nogci.cmp, aes(type, latency)) +
    stat_summary(fun.y=p9999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p9999, geom="errorbar", width=0.05) +
    ggtitle("99.99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ncol=2,
  nrow=2)
```



## Hypothesis tests

Even though the ECDF looked very similar and the confidence intervals seem to intersect, we would like to have an statistical test to check how close the simulator latency is to the experiment latency, which can can be measured by Goodness-of-Fit (GoF) tests. e used
the two-sample Kolmogorov-Smirnov (KS) test, which checks if two that the samples are drawn from the same distribution. 

The KS test has an issue of being sensitive for large samples. As the data samples used are all large ($35,000+$ datapoints), we applied an approach used in other modelling studies to mitigate this issue [this](http://ieeexplore.ieee.org/document/5703090/), [this](http://ieeexplore.ieee.org/document/5367061/) and [Marcus' paper](http://ieeexplore.ieee.org/document/6319153/?reload=true) (more at Marcus' paper, including references to goodness-of-fit tests). We selected $500$ random samples of size $50$ for each fitted data, obtain the p-values for the KS test applied to each sample and then calculate the average p-value.

**Treatment**

```{r cache=F}
mean(bind_rows(
      replicate(
          1000,
          ks.test((al1.cmp %>% filter(type == "Experiment") %>% sample_n(30))$latency, 
                  (al1.cmp %>% filter(type == "Simulator") %>% sample_n(30))$latency),
          simplify = F),
      .id="Obs")$p.value)
```


**Control**

```{r cache=F}
mean(bind_rows(
      replicate(
          1000,
          ks.test((al1.nogci.cmp %>% filter(type == "Experiment") %>% sample_n(30))$latency, 
                  (al1.nogci.cmp %>% filter(type == "Simulator") %>% sample_n(30))$latency),
          simplify = F),
      .id="Obs")$p.value)
```

As p-values are that high we can not refute the null hyphothesis: one *cannot* claim statistical support for a difference.

## Conclusions 

I would say the simulator is valid: one cannot claim its output is statically different from what we observed in our
experiments.

* Boxplot, ECDFs, QQPlots look very close
* Confidence intervals for the median and tail seem to intersect
* The goodness-of-fit test doesnâ€™t allow us to claim the statistical difference

# Appendix

## Experiment setup

* Throughput: 80 per service
* Threads: 1 per service
* Connections: 2 per service
* Message size (amount of memory allocated per request): 204800
* Experiment duration: 120s
* Instance: 2cores, 1GB RAM

## Kolmogorov-Smirnov Two-Sample Test

More references:

* [KS Test in R](https://stats.stackexchange.com/questions/222294/understanding-kolmogorov-smirnov-test-in-r)

* [KS Test in discrete variables](https://stats.stackexchange.com/questions/48317/kolmogorov-smirnov-with-discrete-data-what-is-proper-use-of-dgofks-test-in-r)

* [KS Test](https://onlinecourses.science.psu.edu/stat414/node/234)

* [KS Test](http://www.physics.csbsju.edu/stats/KS-test.html)