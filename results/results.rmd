---
title: "GCI-Java reaches the Cloud"
author: "Daniel Fireman (danielfireman@gmail.com)"
date: "May, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F)
knitr::opts_chunk$set(warning=F)
knitr::opts_chunk$set(cache=F)

require(gridExtra)
require(boot)
require(dplyr)
require(stringr)
require(cowplot)
require(ggplot2)
require(reshape2)

source("functions.R")

SAMPLE_SIZE <- 1000
RESAMPLES <- 1000
WARMUP_SECS <- 120
DURATION_SECS <- 0

q.plot.data <- function(df) {
  q <-  df %>% group_by(trunc(timestamp)) %>% summarize(
    q50 = quantile(request_time, 0.5),
    q90 = quantile(request_time, 0.9),
    q99 = quantile(request_time, 0.99),
    q999 = quantile(request_time, 0.999),
    q9999 = quantile(request_time, 0.9999),
    max = max(request_time))
  q <- melt(q, id="trunc(timestamp)")
  colnames(q) <- c("ts", "func", "value")
  return(q)
}

tp <- function(df){
  return(NROW(df)/(df$timestamp[NROW(df)]-df$timestamp[1]))
}
```

# 1-Intance Experiments

## Design

* Independent variables:
     * Pressure on heap (high::256KB or low::64KB): emulated by the amount of memory heap by each request.
     * State Kept (yes or no): emulated by an simple arrayallocated service startup and updated by every request
     * GCI (on or off)

* Dependent variable:
     * Latency: wall clock time measure from the loadbalancer

## Setup

* 1 service instance (VM with 2 cores and 1GB RAM). Heap set to 512MB.
* 1 machine running client, loadbalancer and proxy (for experiments with GCI on)

# Results

## GCI OFF

How does a simple service without GCI deal with changes in heap pressure and 
keeping state?

```{r read.nogci}
nogci.low.nostate <- accesslog("1i", "nogci_T50_M65536_W0", 1, WARMUP_SECS, DURATION_SECS)
nogci.low.state <- accesslog("1i", "nogci_T50_M65536_W1024", 1, WARMUP_SECS, DURATION_SECS)
nogci.high.nostate <- accesslog("1i", "nogci_T50_M262144_W0", 1, WARMUP_SECS, DURATION_SECS)
nogci.high.state <- accesslog("1i", "nogci_T50_M262144_W256", 1, WARMUP_SECS, DURATION_SECS)
```

```{r}
nogci.cmp <- rbind(
  data.frame("latency"=nogci.low.nostate$succ$request_time, type="OFF", state="Stateless", mem="Low"),
  data.frame("latency"=nogci.low.state$succ$request_time, type="OFF", state="Stateful", mem="Low"),
  data.frame("latency"=nogci.high.state$succ$request_time, type="OFF", state="Stateful", mem="High"),
  data.frame("latency"=nogci.high.nostate$succ$request_time, type="OFF", state="Stateless", mem="High")
)

ggplot(nogci.cmp, aes(state, latency, color=mem)) +
    geom_boxplot() +
    scale_y_continuous(breaks=seq(0,max(nogci.cmp$latency), 10)) +
    ylab("Latency(ms)") +
    theme(axis.title.x=element_blank()) 
```

**Conclusion**: The boxplots above show that, keeping state and increasing heap pressure
have an impact in the latency tail. Bellow we print the 99-th percentile for all cases.

```{r}
print(paste("Statefull & Low Heap Pressure:", quantile(nogci.low.state$succ$request_time, c(0.99))))
print(paste("Statefull & High Heap Pressure:", quantile(nogci.high.state$succ$request_time, c(0.99))))
print(paste("Stateless & Low Heap Pressure:", quantile(nogci.low.nostate$succ$request_time, c(0.99))))
print(paste("Stateless & High Heap Pressure:", quantile(nogci.high.nostate$succ$request_time, c(0.99))))
```

## GCI ON

Does GCI help on improving the situation described above. In other words, does the
tail latency get less affected by the heap pressure and the state kept?

```{r read.gci.on}
gci.low.nostate <- accesslog("1i", "gci_T50_M65536_W0", 1, WARMUP_SECS, DURATION_SECS)
gci.low.state <- accesslog("1i", "gci_T50_M65536_W1024", 1, WARMUP_SECS, DURATION_SECS)
gci.high.nostate <- accesslog("1i", "gci_T50_M262144_W0", 1, WARMUP_SECS, DURATION_SECS)
gci.high.state <- accesslog("1i", "gci_T50_M262144_W256", 1, WARMUP_SECS, DURATION_SECS)
```

```{r}
gci.cmp <- rbind(
  data.frame("latency"=gci.low.nostate$succ$request_time, type="ON", state="Stateless", mem="Low"),
  data.frame("latency"=gci.low.state$succ$request_time, type="ON", state="Stateful", mem="Low"),
  data.frame("latency"=gci.high.state$succ$request_time, type="ON", state="Stateful", mem="High"),
  data.frame("latency"=gci.high.nostate$succ$request_time, type="ON", state="Stateless", mem="High")
)

ggplot(gci.cmp, aes(state, latency, color=mem)) +
    geom_boxplot() +
    scale_y_continuous(breaks=seq(0,max(gci.cmp$latency), 10)) +
    ylab("Latency(ms)") +
    theme(axis.title.x=element_blank()) 
```

**Conclusion**: The boxplots above show that, keeping state and increasing memory pressure
have an impact in the latency tail.

```{r}
print(paste("Statefull & Low Heap Pressure:", quantile(gci.low.state$succ$request_time, c(0.99))))
print(paste("Statefull & High Heap Pressure:", quantile(gci.high.state$succ$request_time, c(0.99))))
print(paste("Stateless & Low Heap Pressure:", quantile(gci.low.nostate$succ$request_time, c(0.99))))
print(paste("Stateless & High Heap Pressure:", quantile(gci.high.nostate$succ$request_time, c(0.99))))
```

## Comparison

### Latency

```{r}
cmp <- rbind(gci.cmp, nogci.cmp)
ggplot(cmp, aes(type, latency)) +
    geom_boxplot() +
    facet_grid(. ~ state +  mem) +
    scale_y_continuous(breaks=seq(0,max(cmp$latency), 10)) +
    ylab("Latency(ms)") +
    theme(axis.title.x=element_blank()) 

ggplot(cmp, aes(latency, linetype=type)) +
  stat_ecdf() +
  facet_grid(. ~ state +  mem) +
  ggtitle("ECDF") +
  xlab("Latency(ms)") +
  ylab("ECDF") +
  scale_x_continuous(breaks=seq(0,max(cmp$latency), 30)) +
  coord_cartesian(ylim = c(0.99, 1)) +
  theme(legend.position="top")
```

### Throughput (off, on)

```{r}
print(paste("Statefull & Low Heap Pressure:", tp(nogci.low.state$succ), tp(gci.low.state$succ)))
print(paste("Statefull & High Heap Pressure:", tp(nogci.high.state$succ), tp(gci.high.state$succ)))
print(paste("Stateless & Low Heap Pressure:", tp(nogci.low.nostate$succ), tp(gci.low.nostate$succ)))
print(paste("Stateless & High Heap Pressure:", tp(nogci.high.nostate$succ), tp(gci.high.nostate$succ)))
```

### Stddev (off, on)

```{r}
print(paste("Statefull & Low Heap Pressure:", sd(nogci.low.state$succ$request_time), sd(gci.low.state$succ$request_time)))
print(paste("Statefull & High Heap Pressure:", sd(nogci.high.state$succ$request_time), sd(gci.high.state$succ$request_time)))
print(paste("Stateless & Low Heap Pressure:", sd(nogci.low.nostate$succ$request_time), sd(gci.low.nostate$succ$request_time)))
print(paste("Stateless & High Heap Pressure:", sd(nogci.high.nostate$succ$request_time), sd(gci.high.nostate$succ$request_time)))
```

### IQR (off, on)

```{r}
print(paste("Statefull & Low Heap Pressure:", IQR(nogci.low.state$succ$request_time), IQR(gci.low.state$succ$request_time)))
print(paste("Statefull & High Heap Pressure:", IQR(nogci.high.state$succ$request_time), IQR(gci.high.state$succ$request_time)))
print(paste("Stateless & Low Heap Pressure:", IQR(nogci.low.nostate$succ$request_time), IQR(gci.low.nostate$succ$request_time)))
print(paste("Stateless & High Heap Pressure:", IQR(nogci.high.nostate$succ$request_time), IQR(gci.high.nostate$succ$request_time)))
```








<!-- ```{r} -->
<!-- al1.exp.gci.warm <- accesslog("1i", "gci_T50_M65536_W0", 1, WARMUP_SECS) -->
<!-- #al1.exp.gci.warm <- accesslog("1i", "gci_T50_M262144_W256", 1, WARMUP_SECS, DURATION_SECS) -->
<!-- al1.exp.gci <- filter(al1.exp.gci.warm, status == 200) -->

<!-- print(paste("Number of succeeded requests (GCI ON): ", NROW(al1.exp.gci) , "(", (NROW(al1.exp.gci)/NROW(al1.exp.gci.warm))*100,"%)")) -->
<!-- print(paste("IQR (GCI ON): ", IQR(al1.exp.gci$request_time))) -->
<!-- print(paste("STDDEV (GCI ON): ",  sd((al1.exp.gci$request_time)))) -->
<!-- print(paste("MAX THROUGHPUT (GCI ON): ", NROW(al1.exp.gci)/(al1.exp.gci$timestamp[NROW(al1.exp.gci)]-al1.exp.gci$timestamp[1]))) -->
<!-- summary(al1.exp.gci$request_time) -->
<!-- quantile (al1.exp.gci$request_time, c(0.9,0.99,0.999,0.9999,0.99999)) -->

<!-- failed.requests.gci <- filter(al1.exp.gci.warm, status == 503) -->
<!-- print(paste("Number of failed requests (GCI ON): ", NROW(failed.requests.gci), "(", (NROW(failed.requests.gci)/NROW(al1.exp.gci.warm))*100, "% )")) -->
<!-- if (NROW(failed.requests.gci) > 0) { -->
<!--   summary(failed.requests.gci$request_time) -->
<!--   hist(failed.requests.gci$request_time) -->
<!-- } -->

<!-- hist(al1.exp.gci$request_time) -->

<!-- ggplot() + -->
<!--   geom_point(data = al1.exp.gci, aes(x = timestamp, y = request_time))+ -->
<!--   scale_x_continuous(breaks=seq(0,max(al1.exp.gci$timestamp),20)) + -->
<!--   ylab("Latência (ms)") + -->
<!--   xlab("Andamento do experimento (s)") -->

<!-- ggplot() + -->
<!--   geom_line(data = q.plot.data(al1.exp.gci), aes(x = ts, y = value, color = func))+ -->
<!--   scale_x_continuous(breaks=seq(0,max(al1.exp.gci$timestamp),5)) + -->
<!--   ylab("Latência (ms)") + -->
<!--   xlab("Andamento do experimento (s)") -->

<!-- cpu <- read.csv("1i/cpu_gci_T50_M65536_W0_0_1.csv") -->
<!-- ggplot() + -->
<!--   geom_point(data = cpu, aes(x = ts, y = load/2))+ -->
<!--   ylab("Carga CPU (%)") + -->
<!--   xlab("Andamento do experimento (s)") -->
<!-- ``` -->
<!-- ```{r} -->
<!-- #al1.exp.nogci.warm <- accesslog("1i", "nogci_T100_M65536_W1024", 1 , WARMUP_SECS) -->
<!-- al1.exp.nogci.warm <- accesslog("1i", "nogci_T50_M262144_W256", 1 , WARMUP_SECS, DURATION_SECS) -->
<!-- al1.exp.nogci <- filter(al1.exp.nogci.warm, status == 200) -->
<!-- print(paste("Number of succeeded requests (GCI OFF): ", NROW(al1.exp.nogci))) -->
<!-- print(paste("IQR (GCI OFF): ", IQR(al1.exp.nogci$request_time))) -->
<!-- print(paste("STDDEV (GCI OFF): ",  sd((al1.exp.nogci$request_time)))) -->
<!-- print(paste("MAX THROUGHPUT (GCI OFF): ", NROW(al1.exp.nogci)/(al1.exp.nogci$timestamp[NROW(al1.exp.nogci)]-al1.exp.nogci$timestamp[1]))) -->
<!-- print(paste("NUM 99.99 (GCI OFF): ",  NROW(al1.exp.nogci)*0.001)) -->
<!-- print(paste("NUM 99.999 (GCI OFF): ",  NROW(al1.exp.nogci)*0.0001)) -->
<!-- summary(al1.exp.nogci$request_time) -->
<!-- quantile (al1.exp.nogci$request_time, c(0.9,0.99,0.999,0.9999,0.99999)) -->

<!-- hist(al1.exp.nogci$request_time) -->

<!-- failed.requests.gci <- filter(al1.exp.nogci.warm, status == 503) -->
<!-- print(paste("Number of failed requests (GCI ON): ", NROW(failed.requests.gci), "(", (NROW(failed.requests.gci)/NROW(al1.exp.nogci.warm))*100, "% )")) -->
<!-- if (NROW(failed.requests.gci) > 0) { -->
<!--   summary(failed.requests.nogci$request_time) -->
<!--   hist(failed.requests.nogci$request_time) -->
<!-- } -->

<!-- ggplot() + -->
<!--   geom_point(data = al1.exp.nogci, aes(x = timestamp, y = request_time))+ -->
<!--   scale_x_continuous(breaks=seq(0, max(al1.exp.nogci$timestamp),5)) + -->
<!--   ylab("Latência (ms)") + -->
<!--   xlab("Andamento do experimento (s)") -->

<!-- ggplot() + -->
<!--   geom_line(data = q.plot.data(al1.exp.nogci), aes(x = ts, y = value, color = func))+ -->
<!--   ylab("Latência (ms)") + -->
<!--   xlab("Andamento do experimento (s)") -->

<!-- cpu <- read.csv("1i/cpu_nogci_T50_M262144_W0_0_1.csv") -->
<!-- ggplot() + -->
<!--   geom_point(data = cpu, aes(x = ts, y = load/2))+ -->
<!--   ylab("Carga CPU (%)") + -->
<!--   xlab("Andamento do experimento (s)") -->
<!-- ``` -->

<!-- ```{r, fig.asp=0.5, fig.align="center"} -->
<!-- #a1 <- al1.exp.gci %>% filter(request_time >= quantile(al1.exp.gci$request_time, 0.99)) -->
<!-- #a2 <- al1.exp.nogci %>% filter(request_time >= quantile(al1.exp.nogci$request_time, 0.99)) -->
<!-- al1.cmp <- rbind( -->
<!--   data.frame("latency"=al1.exp.gci$request_time, type="ON"), -->
<!--   data.frame("latency"=al1.exp.nogci$request_time, type="OFF")) -->


<!-- grid.arrange( -->
<!--   ggplot(al1.cmp, aes(type, latency)) + -->
<!--     geom_boxplot() + -->
<!--     ggtitle("Summary") + -->
<!--     scale_y_continuous(breaks=seq(0,max(al1.cmp$latency), 20)) + -->
<!--     ylab("Latency(ms)") + -->
<!--     xlab("GCI"), -->
<!--    ggplot(al1.cmp, aes(latency, linetype=type)) + -->
<!--     stat_ecdf() + -->
<!--     ggtitle("ECDF") + -->
<!--     xlab("Latency(ms)") + -->
<!--     ylab("ECDF") + -->
<!--     scale_x_continuous(breaks=seq(0,max(al1.cmp$latency), 20)) + -->
<!--     coord_cartesian(ylim = c(0.99, 1)) + -->
<!--     theme(legend.position="top"), -->
<!--   ncol=2) -->
<!-- ``` -->
<!-- ```{r, fig.asp=0.5, fig.align="center"} -->
<!-- #If you don't trim the library, your computer could die trying to resample. -->
<!-- al1.cmp <- rbind( -->
<!--   data.frame("latency"=sample(al1.exp.gci$request_time, SAMPLE_SIZE), type="ON"), -->
<!--   data.frame("latency"=sample(al1.exp.nogci$request_time, SAMPLE_SIZE), type="OFF")) -->


<!-- grid.arrange( -->
<!--   ggplot(al1.cmp, aes(type, latency)) + -->
<!--     stat_summary(fun.y=median, geom="point", shape=23, size=2) + -->
<!--     stat_summary(fun.data=ci.median, geom="errorbar", width=0.05) + -->
<!--     ggtitle("Median") + -->
<!--     ylab("Latency(ms)") + -->
<!--     xlab("GCI"), -->
<!--   ggplot(al1.cmp, aes(type, latency)) + -->
<!--     stat_summary(fun.y=p99, geom="point", shape=23, size=2) + -->
<!--     stat_summary(fun.data=ci.p99, geom="errorbar", width=0.05) + -->
<!--     ggtitle("99 Percentile") + -->
<!--     ylab("Latency(ms)") + -->
<!--     xlab("GCI"), -->
<!--   ggplot(al1.cmp, aes(type, latency)) + -->
<!--     stat_summary(fun.y=p999, geom="point", shape=23, size=2) + -->
<!--     stat_summary(fun.data=ci.p999, geom="errorbar", width=0.05) + -->
<!--     ggtitle("99.9 Percentile") + -->
<!--     ylab("Latency(ms)") + -->
<!--     xlab("GCI"), -->
<!--   ggplot(al1.cmp, aes(type, latency)) + -->
<!--     stat_summary(fun.y=p9999, geom="point", shape=23, size=2) + -->
<!--     stat_summary(fun.data=ci.p9999, geom="errorbar", width=0.05) + -->
<!--     ggtitle("99.99 Percentile") + -->
<!--     ylab("Latency(ms)") + -->
<!--     xlab("GCI"), -->
<!--   ggplot(al1.cmp, aes(type, latency)) + -->
<!--     stat_summary(fun.y=p99999, geom="point", shape=23, size=2) + -->
<!--     stat_summary(fun.data=ci.p99999, geom="errorbar", width=0.05) + -->
<!--     ggtitle("99.999 Percentile") + -->
<!--     ylab("Latency(ms)") + -->
<!--     xlab("Type"), -->
<!--   ncol=3, -->
<!--   nrow=2) -->
<!-- ``` -->

